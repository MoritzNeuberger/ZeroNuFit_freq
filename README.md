profile likelihood fit for GERDA by B. Schwingenheuer
Math is explained in GSTR-18-013
-----------------------------------------------------


The 'data input' files are
--------------------------

bkg_all.txt  =  background index for data sets of Phase I and a common value for Phase II
                  in units  cnt/(keV kg yr)
		  format =  bkg_name , index
		  bkg_name is a fit parameter

  parameter_all.txt =  partition information
    format:  one line with time stamp interval starting with 't'
             followed by a line for each detector which includes the daq_channel, det_name, resolution, error_of_resolution,
	     efficiency, error_of_eff, exposure,  energy_shift_SEP, error_shift, bkg_name, systematic_name
     phase I is included as "det_name"  'coax' and 'bege' with different time stamps for 'golden', 'silver' and 'extra'
     systematic_name  is 'sys1' or 'sys2'  for Phase I and II, i.e. systematic errors are treated independently
     (and uncorrelated) between PI and PII --> 2 * 3  systematic uncertainties = scale factors

  events_all.txt = event list from data,  format = det_name  timestamp  energy  bkg_name
      det_name and timestamp  are used to find the partition parameters, bkg_name is used to find the correct
      fit parameter for the background index

  Note:  unit of inverse half-life 1/T is   1E-25/yr

-----------------------------------------------------------------------

code: subroutines
--------------------

pf.C and pf.h    contain the basic  functions and declarations  used by the different main programs.
      These are the FCN routine used by MINUIT, the routine to read in the TXT files, the routine to generate toy MC data
      samples,
      the functions that calculate the profile likelihood and T1/2 limit

important functions called by the user are:
      initfit:  reads in all parameter, ... files, bit pattern for systematic error evaluation,
                initializes MINUIT,
		also reads in the ROOT file with 90% quantile distribution as a fct of 1/T, this root file
		is generated by the main programs  cover2 and pval

      generate_sample: generates toy MC data sets according to the parameters specified (background, resolution, signal strength)

      profile:  input=1/T,  performs the fit, returns  profile likelihood, also returns  best_fit 1/T in the argument list 

      scanfit: returns the  likelihood distribution as a function of 1/T,  points where the likelihood becomes
               larger than the '90% limit distribution' are the returned '90% limit': 2-sided limit, i.e. if the best
	       fit 1/T is large  then there might be 2 points (lower and higher than best fit 1/T) where likelihood passes
	       the '90% limit distribution'
---------------------------------------------------------------------------

Main routines and analysis flow:
--------------------------------
cover2.C:    scans 1/T from 0 to a max value (units always 1E-25/yr) in steps of 'binwidth'
         for every value of 1/T a number of  toyMC data samples are generated given the background
	 and signal strength according to 1/T, background index ...
	 For every toy MC the  test statistic is calculated as a fct of 1/T.
	 The result (= pair of  1/T, test statistic)  is stored in an ntuple.

         The parameter txt file names are hard coded in the char variable fparameter (for data partitions),
	 bparameter (for background index) and rparameter (input root file, actually not relevant
	 for this step of the analysis chain),

         On the command line the directory name and output file name can be specified.
	 This allows to submit many jobs in parallel in a batch queue.
	 Need typically >200k toyMC per 1/T value.


pval.C:  reads in ROOT output files from 'cover2.C' and sorts for every 1/T all test statistics.
        The names of cover2 output files must be entered by hand like  mc->Add(..)

        Output is a root file with the histogram 'hlim' = 90% quantile of test
	  statistics as a function of 1/T --> needed for limit setting, read in by subroutine initfit.

        This program also contains code to generate data (= TGraph) for p-value plot for limit setting
	sensitivity  -->
	  reads in output of sensit3 and sorts them to find 1sigma and 2sigma quantile distribution 
          reads in output from t12limit to calculate the  pvalue for  data
	  stored TGraphs for all distributions

t12limit.C  calculates data  90% CL limit
          In the function call to 'initfit' the data parameter files and the histogram
	       output of  pval.C  is read in
	  The program calculates the test statistics as a fct of 1/T (call to scanfit)
	  Stores data test statistics distribution in file, prints limit to screen

sensit3.C  calculates sensitivity of experiment for limit setting by generating toy MC without signal

         fct call to initfit  contains all input parameters,
	 calls scanfit to get test statistics as fct of 1/T for every toy MC
	 ntuple with (1/T, test statistics) for all toy MC --> for pval.C
	 fills histogram 'hh' with 90% limit for every toy MC and calculates/prints median limit = sensitivity


discover.C  calculates sensitivity for signal discovery, first step = generate many
            toyMC spectra and write out test statistics,
	    this program is designed for batch mode operation (like cover2)
	    parameters -d for directory name where all input files are   and -o for root output filename

         for every 1/T generate toy MC spectrum (expected bkg and signal count from parameters like
            efficiency, bkg index, energy resolution)
	 calculate t= profile likelihood for  1/T=0 (no signal) and fill pair (1/T, t)  in ntuple,
	 
discover2.C   calculates the actual discovery sensitivity
        - first reads in  test statistics calculated e.g. by cover2 for 1/T=0,
	  then find the value of the test statistic that is the 99.7% quantile
        - second read in the root tree generated by discover.C
	  calculate the fraction of toyMC with profile likelihood > 99.7% quantile for "bkg only, 1/T=0"
	 - also use a different method suggested by Matto = p value of the median  using the
	   "bkg only"  distribution of profile likelihoods
	 - output are the histograms and TGraphs


pvalueplot.C   makes the pvalue plot using all stored TGraph

	   